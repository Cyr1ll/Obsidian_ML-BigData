#Метрики #Классификация
## Введение

Метрики качества классификации позволяют оценить, насколько хорошо модель классифицирует объекты. Они сравнивают предсказанные моделью значения с реальными метками классов, чтобы измерить точность и эффективность модели.
Почитать - https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii

---

## Основные метрики

### Матрица ошибок (Confusion Matrix)
Матрица ошибок — это таблица, которая показывает распределение правильных и ошибочных предсказаний:
- **True Positive (TP)**: Правильно классифицированные положительные объекты.
- **True Negative (TN)**: Правильно классифицированные отрицательные объекты.
- **False Positive (FP)**: Ошибочно классифицированные как положительные.
- **False Negative (FN)**: Ошибочно классифицированные как отрицательные.

![[662c42677529a0f4e97e4f96_644aea65cefe35380f198a5a_class_guide_cm08.png | 500]]
---

### Accuracy (Точность)
$$ Accuracy = \frac{TP + TN}{TP + TN + FP + FN} $$
- Показывает долю правильно классифицированных объектов от общего числа.

---

### Precision (Точность для положительного класса)
$$ Precision = \frac{TP}{TP + FP} $$
- Показывает долю истинно положительных объектов среди всех, предсказанных как положительные.

---

### Recall (Полнота)
$$ Recall = \frac{TP}{TP + FN} $$
- Показывает долю истинно положительных объектов, которые модель смогла найти.

---

### F1-мера
$$ F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall} $$
- Гармоническое среднее между точностью (Precision) и полнотой (Recall).
- Используется, когда важно учитывать баланс между FP и FN.

---

### ROC-AUC (Receiver Operating Characteristic — Area Under Curve)
- **ROC-кривая**: График, показывающий зависимость между TPR (True Positive Rate) и FPR (False Positive Rate) при различных порогах классификации.
- **AUC (Area Under Curve)**: Площадь под ROC-кривой.
  $$
  TPR = \frac{TP}{TP + FN}, \, FPR = \frac{FP}{FP + TN}
  $$
- Чем ближе значение AUC к 1, тем лучше модель.

---

### Log Loss (Логарифмическая функция потерь)
$$ LogLoss = -\frac{1}{N} \sum_{i=1}^{N} \left[ y_i \cdot \log(p_i) + (1 - y_i) \cdot \log(1 - p_i) \right] $$
- Используется для оценки вероятностных моделей. Чем меньше значение Log Loss, тем точнее предсказания модели.

---

## Примеры применения метрик
1. **Accuracy**:
   - Используется, когда классы сбалансированы.
2. **Precision и Recall**:
   - Важны в задачах, где критично избегать ошибок одного типа (например, медицинские диагнозы или обнаружение мошенничества).
3. **ROC-AUC**:
   - Применяется для моделей, выдающих вероятности принадлежности к классам.
4. **Log Loss**:
   - Используется при построении вероятностных моделей для сравнения точности.

---

## Связанные темы
- [[Задача регрессионного анализа и классификации(14)]]
- [[24Линейный классификатор(24)]]
- [[26Парзеновские окна(26)]]
- [[48Метод опорных векторов SVM(48)]]
- [[45Метод ближайших соседей kNN(46)]]
- [[52Наивный Байесовский классификатор(52)]]
- [[59Алгоритм ID3(59)]]
- [[60Случайный лес. Bagging. Stacking(60)]]
- [[53Полиномиальный наивный байес(53)]]
- [[57Алгоритм Cart]]
- [[58Алгоритм С4.5]]
- [[55Гауссовский наивный байес(55)]]
- [[54Наивная байесовская классификация Бернулли(54)]]
- [[25Обобщенный метрический классификатор(25)]]