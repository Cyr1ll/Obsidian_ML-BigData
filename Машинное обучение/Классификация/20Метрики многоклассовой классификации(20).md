# Многоклассовая классификация

## Введение
Многоклассовая классификация — это задача классификации, в которой число классов $K > 2$. Для оценки качества модели метрики становятся сложнее из-за необходимости учитывать все классы одновременно. 

Часто задача классификации на $K$ классов преобразуется в $K$ задач бинарной классификации, где каждый класс $i$ отделяется от остальных $(i = 1, \dots, K)$. Для каждой задачи можно построить свою матрицу ошибок. Итоговое значение метрики рассчитывается двумя основными способами.

## Методы усреднения метрик
1. **Микроусреднение (Micro-averaging)**:
   - Сначала усредняются элементы матриц ошибок (TP, FP, TN, FN) между всеми бинарными классификаторами.
   - Затем на основе одной общей усреднённой матрицы рассчитываются метрики (Precision, Recall, F1).
   - **Формула** для $TP$:
     $$
     TP = \frac{1}{K} \sum_{i=1}^K TP_i
     $$

2. **Макроусреднение (Macro-averaging)**:
   - Сначала рассчитываются метрики (Precision, Recall, F1) для каждого бинарного классификатора отдельно.
   - Затем результаты усредняются.
   - В этом подходе вклад каждого класса в итоговую метрику одинаковый, независимо от размера класса.

## Влияние на метрики при дисбалансе классов
- Микроусреднение делает вклад маленьких классов в общую метрику незаметным, так как усредняются абсолютные значения (счётчики объектов).
- Макроусреднение учитывает нормированные величины (например, Precision для каждого класса), что делает вклад редких классов более заметным.

### Пример
Рассмотрим задачу классификации объектов трёх цветов: жёлтого, зелёного и синего. 
- Жёлтый: 21 объект.
- Зелёный: 20 объектов.
- Синий: 4 объекта.
![[Pasted image 20250117114758.png]]

Матрица ошибок модели:
| Класс предсказания → | Жёлтый | Зелёный | Синий |
|-----------------------|--------|---------|-------|
| **Истинный класс ↓**  |        |         |       |
| Жёлтый                | 20     | 0       | 1     |
| Зелёный               | 5      | 19      | 0    |
| Синий                 | 0      | 1       | 0       |

![[Pasted image 20250117114815.png]]
#### Precision
1. **Микроусреднение**:
   $$
   Precision = \frac{1}{3} (20 + 0 + 19) / \frac{1}{3} (20 + 0 + 19 + 5 + 1 + 0) = 0.87
   $$

2. **Макроусреднение**:
   $$
   Precision = \frac{1}{3} \left( \frac{20}{20+5} + \frac{0}{0+1} + \frac{19}{19+0} \right) = 0.6
   $$

### Вывод
- Микроусреднение показывает общее качество классификации, но оно скрывает влияние редких классов.
- Макроусреднение лучше отражает, что модель плохо справляется с редкими классами, такими как синий цвет, которого в датасете мало.
