# Полиномиальный наивный байес

## Определение
Полиномиальный наивный байес (Multinomial Naive Bayes, MNB) — это классификационный алгоритм, который использует вероятностный подход для классификации объектов на основе признаков. Он является расширением наивного байеса, где вероятность каждого класса моделируется с использованием полиномиального распределения.

## Применение
- Подходит для задач классификации, где данные имеют дискретные признаки (например, в текстовых данных, когда признаки — это слова).
- Особенно эффективен в задачах, связанных с классификацией текстов, таких как спам-фильтрация и анализ тональности.

## Математика
Полиномиальный наивный байес моделирует вероятность $P(C_k | X)$ с использованием формулы Байеса:
$$
P(C_k | X) = \frac{P(C_k) P(X | C_k)}{P(X)}
$$
где:
- $P(C_k)$ — априорная вероятность класса $C_k$.
- $P(X | C_k)$ — вероятность наблюдения признаков $X = (x_1, x_2, \dots, x_n)$ при условии класса $C_k$.
- $P(X)$ — маргинальная вероятность наблюдения признаков (независимо от класса).

Для полиномиального распределения $P(X | C_k)$ можно выразить как:
$$
P(X | C_k) = \prod_{i=1}^{n} \frac{(N_{i,k})!}{x_i! (N_{i,k} - x_i)!} p_{i,k}^{x_i} (1 - p_{i,k})^{N_{i,k} - x_i}
$$
где $N_{i,k}$ — количество признаков $x_i$ в классе $C_k$, а $p_{i,k}$ — вероятность появления признака $x_i$ в классе $C_k$.

## Преимущества и недостатки
- **Преимущества**: Простота, высокая скорость обучения и прогнозирования, хорошая производительность при текстовых данных.
- **Недостатки**: При сильных зависимостях между признаками может не работать так хорошо, как более сложные модели.

## Пример
Для классификации текстов на спам и не-спам можно использовать полиномиальный наивный байес с частотами слов как признаками.
