# Алгоритм CART  

## Основная идея  
CART (Classification and Regression Trees) – это алгоритм обучения деревьев решений, который позволяет работать как с дискретными, так и с непрерывными целевыми переменными. Таким образом, он может решать задачи как классификации, так и регрессии.  

Основные особенности:  
- Алгоритм строит бинарные деревья решений (в каждом узле только два потомка).  
- Для оценки качества разделения данных используется **индекс Джини** или **энтропия**.  

---

## Индекс Джини и энтропия  
**![|500](https://lh7-rt.googleusercontent.com/docsz/AD_4nXd-iWz_eH5paboRX8lMxbQ4uV3JqQtTN1nyAb464xzZsrDS6aAS0KZHVJ0pQUE_pUpRYO82X_uABwTrTDtmkRXZb8V4WC_WN4hfvFvFrextM5mBAzWcKucuyhDivK5Q-YAN_zGh9VDwjxMscMWs2uz7bpeV?key=C1AMzwFdvttb7H1YBkknyQ)**
**![|500](https://lh7-rt.googleusercontent.com/docsz/AD_4nXee1XRBUQv7vU-Qh0uwRQVI4nGyEaWZSEmok6QXstYxjYdT72yZPYFeBV5fpgg6J12N-1Q1yTNEZ-HCdsVDFu7rc1nS9_h4RzHkNsWi6QAKeCe2BKjLS0Xt8VNuX2PmF5NwvlJ4Xuh1hNXlamzYIXeo0I3e?key=C1AMzwFdvttb7H1YBkknyQ)**
1. **Индекс Джини**  
   - Мера неоднородности выборки.  
   - Чем ниже значение индекса Джини, тем более однородна выборка.  
   - CART минимизирует средневзвешенный индекс Джини двух полученных выборок после разделения.  

   Формула индекса Джини:  
   $$  
   G(S) = 1 - \sum_{i=1}^n P_i^2,  
   $$  
   где $P_i$ – вероятность принадлежности к классу $i$.  

2. **Энтропия**  
   - Мера неопределённости выборки.  
   - Минимизация энтропии может привести к отличным от индекса Джини результатам, особенно для несбалансированных выборок.  

   Формула энтропии:  
   $$  
   H(S) = - \sum_{i=1}^n P_i \log_2(P_i).  
   $$  

---

## Критерии остановки алгоритма CART  
1. Достигнута **максимальная глубина дерева**.  
2. Количество элементов в узле меньше порогового значения.  
3. Найденное разделение не улучшает качество модели по сравнению со случайным выбором.  
4. Выборка в узле уже однородна (все элементы принадлежат одному классу).  

---
**![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXcAZxe83wdBM6X08KD6nINxevIHjg1gFDYNfbbuW4ggyoQ5sOfBM5brDGwjVXFrK33KFaDwXbINwNUWEvKC_30nUsIcsA8dSvXZc4QQWhCHeeVMzgJ8yKbmN2Q-hlSqPjZ3Wq6h_tfZro68nuJop2aA38GI?key=C1AMzwFdvttb7H1YBkknyQ)**
## Преимущества алгоритма CART  
- **Простота интерпретации**: деревья решений легко визуализировать и объяснять, так как они представляют собой последовательность логических решений.  
- **Универсальность**: подходит как для задач классификации, так и для регрессии.  
- **Работа с различными типами данных**: поддерживает категориальные и числовые признаки.  
- **Устойчивость к выбросам**: алгоритм не чувствителен к выбросам в данных.  

## Недостатки алгоритма CART  
- **Склонность к переобучению**: деревья могут переобучаться, особенно при большой глубине.  
- **Чувствительность к данным**: небольшие изменения в данных могут привести к значительным изменениям в структуре дерева.  
- **Неэффективность на больших данных**: построение дерева может быть ресурсоёмким при больших объёмах данных.  
