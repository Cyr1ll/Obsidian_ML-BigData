
## Определение
Линейный классификатор – это алгоритм, применяемый для решения задач классификации и регрессии. Его суть заключается в построении линии (в 2D), плоскости (в 3D) или гиперплоскости (в пространстве большей размерности), разделяющей данные на классы.  

**Гиперплоскость** – это подпространство, размерность которого на 1 меньше, чем размерность объемлющего пространства. Например:
- В 2D гиперплоскостью является **прямая**.
- В 3D гиперплоскостью является **плоскость**.

---

## Пример
На рисунке ниже изображена разделяющая гиперплоскость (красная линия), которая разделяет объекты двух классов: круги и квадраты.
![[Pasted image 20250116174757.png]]

**Рис. 1 – Разделяющая гиперплоскость**

---

## Формальное описание
Линейный классификатор принимает следующий вид:
$$
y = \text{sign}\left(\sum_{i=1}^n w_i x_i - w_0 \right) = \text{sign}\left(\langle w, x \rangle - w_0 \right),
$$
где:
- $x = (x_1, \dots, x_n)$ — вектор признаков объекта $x$;
- $w = (w_1, \dots, w_n) \in \mathbb{R}^n$ — вектор параметров классификатора;
- $w_0 \in \mathbb{R}$ — пороговое значение (bias);
- $\langle w, x \rangle$ — скалярное произведение.

---

## Задача обучения
Задача линейного классификатора заключается в подборе вектора $w$ и значения $w_0$ так, чтобы минимизировать число ошибок. Формально, это можно записать так:
$$
\sum_{i=1}^n \left[ y_i \left(\langle w, x_i \rangle - w_0 \right) \leq 0 \right] = 0,
$$
где:
- $y_i$ — истинный класс объекта $x_i$;
- $\langle w, x \rangle = w_0$ — уравнение разделяющей гиперплоскости.

---

## Подходы к обучению
Существуют два основных подхода к обучению линейных классификаторов:
1. **Дискриминативный подход**:
   - Фокусируется на улучшении качества классификации на обучающем наборе данных.
   - Примеры: [[Логистическая регрессия(40)]], метод опорных векторов (SVM).

2. **Генеративный подход**:
   - Основан на моделировании условного распределения классов.
   - Пример: Линейный дискриминантный анализ (LDA).

---

## Примечания
- Линейные классификаторы хорошо работают на линейно разделимых данных.
- Если данные не разделимы линейно, используют ядровые методы, которые преобразуют данные в более высокое пространство признаков.
