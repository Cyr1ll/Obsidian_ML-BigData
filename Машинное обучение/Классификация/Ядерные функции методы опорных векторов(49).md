# Ядерные функции в методах опорных векторов (SVM)
#SVM
## Введение
Ядерные функции позволяют применять **метод опорных векторов (SVM)** к нелинейным задачам классификации и регрессии. Основная идея ядрового метода — перенести данные в пространство большей размерности, где они становятся линейно разделимыми, без необходимости вычислять явное преобразование признаков.

---

## Основная идея

### Функция преобразования
Пусть исходное пространство признаков обозначено как $\mathbb{R}^d$, а преобразованное пространство — как $\mathbb{R}^D$, где $D \gg d$. Для каждого объекта $x \in \mathbb{R}^d$ функция преобразования $\phi(x)$ переносит его в более сложное пространство.

![[Pasted image 20250117122047.png]]
---

### Ядерный трюк
Ядерная функция $K(x_i, x_j)$ позволяет вычислять скалярное произведение в пространстве $\mathbb{R}^D$ без явного вычисления $\phi(x)$:
$$
K(x_i, x_j) = \phi(x_i) \cdot \phi(x_j).
$$

Использование ядрового трюка делает SVM вычислительно эффективным, так как не требует прямого преобразования объектов.

---

## Требования к ядровой функции
Для корректной работы алгоритма SVM ядровая функция $K(x_i, x_j)$ должна быть:
1. **Симметричной**: $K(x_i, x_j) = K(x_j, x_i)$.
2. **Положительно полуопределенной**: $\sum_{i,j} c_i c_j K(x_i, x_j) \geq 0$ для любых коэффициентов $c_i$.

---

## Популярные виды ядерных функций

1. **Линейное ядро**:
   $$K(x_i, x_j) = x_i \cdot x_j.$$
   Используется для линейно разделимых данных. Простое и эффективное, но не подходит для сложных разделений.

2. **Полиномиальное ядро**:
   $$K(x_i, x_j) = (x_i \cdot x_j + c)^d,$$
   где $c$ — константа, $d$ — степень полинома.
   - Позволяет учитывать нелинейные зависимости.
   - Пример: квадратичные ($d=2$) и кубические ($d=3$) ядра.

3. **Радиально-базисное ядро (RBF, гауссово)**:
   $$K(x_i, x_j) = \exp\left(-\gamma ||x_i - x_j||^2\right),$$
   где $\gamma$ — параметр, отвечающий за ширину гауссиана.
   - Универсальное ядро для нелинейных задач.
   - Эффективно, когда классы имеют сложные границы разделения.

4. **Сигмоидное ядро**:
   $$K(x_i, x_j) = \tanh(\alpha x_i \cdot x_j + c),$$
   где $\alpha$ и $c$ — параметры ядра.
   - Похоже на активационную функцию в нейронных сетях.
   - Реже используется из-за сложности подбора параметров.

5. **Ядро на основе расстояния**:
   Например, **лапласовское**:
   $$K(x_i, x_j) = \exp\left(-\frac{||x_i - x_j||}{\sigma}\right).$$

6. **Специфические ядра**:
   Используются для задач со структурированными данными, например текстами, графами или временными рядами:
   - Ядро последовательностей.
   - Ядро для графов.
   - Ядро для временных рядов.

---

## Выбор ядра
Выбор ядра зависит от:
- природы данных (линейные или нелинейные зависимости),
- размерности данных,
- вычислительных затрат.

### Советы по выбору ядра:
- Если данные линейно разделимы — используйте линейное ядро.
- Если границы разделения сложные, попробуйте RBF или полиномиальное ядро.
- Для текстовых данных часто используют линейное ядро (например, в задачах классификации документов).

---

## Алгоритм работы SVM с ядровой функцией
1. **Препроцессинг данных**:
   - Нормализация или стандартизация признаков.
2. **Определение ядра**:
   - Выбор подходящей функции $K(x_i, x_j)$.
3. **Оптимизация**:
   - Решение задачи минимизации с использованием ядерной матрицы:
     $$\min \frac{1}{2} \sum_{i,j} \alpha_i \alpha_j y_i y_j K(x_i, x_j) - \sum_{i} \alpha_i,$$
     где $\alpha_i$ — множители Лагранжа.
4. **Классификация**:
   - Для нового объекта $x$ прогноз делается по знаку функции:
     $$
     f(x) = \text{sign}\left(\sum_{i=1}^n \alpha_i y_i K(x_i, x) + b\right).
     $$

---

## Пример использования

### Данные
Допустим, у нас есть два класса, которые нелинейно разделимы. Мы применяем RBF-ядро:
1. Вычисляем матрицу ядра $K(x_i, x_j)$.
2. Оптимизируем $w$ и $b$ в новом пространстве.
3. Классифицируем новые объекты с помощью функции $f(x)$.

---

## Преимущества и недостатки ядерных методов

### Преимущества
1. Позволяют эффективно решать нелинейные задачи.
2. Гибкость в выборе ядровой функции.
3. Возможность работы с высокоразмерными данными.

### Недостатки
1. Сложность выбора ядра и настройки параметров.
2. Высокая вычислительная сложность для больших данных.
3. Трудности с интерпретацией результатов.

---

## Полезные ссылки
- https://scikit-learn.org/stable/modules/svm.html#
- https://habr.com/ru/articles/802185/
